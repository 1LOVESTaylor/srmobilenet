{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pickle as pk\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Option(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Option()\n",
    "opt.max_epochs = 100000\n",
    "opt.gpu_ids = [0]\n",
    "opt.task = 'train'\n",
    "opt.display_port = 8097\n",
    "opt.num_images_per_batch = 8\n",
    "opt.save_dir = '/home/guang/SuperRes/pytorch-srgan/snapshots/'\n",
    "opt.pretrained_state = None #'/home/guang/SuperRes/pytorch-srgan/snapshots/nocturnal/state_epoch2_iter0.pkl' \n",
    "opt.snapshot_subdir = 'nightingale'\n",
    "opt.snapshot_prefix_G = 'unet256'\n",
    "opt.snapshot_prefix_D = 'basic'\n",
    "opt.snapshot_interval_epochs = 20 # In epochs\n",
    "opt.snapshot_interval_iters = 5000\n",
    "opt.display_interval = 4  # In iterations\n",
    "opt.display_env = opt.snapshot_subdir\n",
    "opt.num_average_minibatches = None \n",
    "opt.learning_rate = 1e-4\n",
    "opt.lambda_G = 1e-3\n",
    "opt.no_lsgan = True\n",
    "opt.dataset = 'starcraft1688' #'ilsvrc2012'\n",
    "opt.num_crops_per_image = 2\n",
    "opt.log_file = os.path.join('/home/guang/SuperRes/pytorch-srgan/snapshots/', \n",
    "                            opt.snapshot_subdir,\n",
    "                            'log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.save_dir = os.path.join(opt.save_dir, opt.snapshot_subdir)\n",
    "if opt.task == 'train':\n",
    "    if not os.path.isdir(opt.save_dir):\n",
    "        os.makedirs(opt.save_dir)\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"pytorch-srgan\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "\n",
    "log_file = logging.FileHandler(opt.log_file)\n",
    "log_file.setLevel(logging.DEBUG)\n",
    "\n",
    "fmt = '%(asctime)s %(levelname)-8s: %(message)s'\n",
    "fmt = logging.Formatter(fmt)\n",
    "\n",
    "log_file.setFormatter(fmt)\n",
    "logger.addHandler(log_file)\n",
    "\n",
    "logger.info('Pretrained state \"{}\"'.format(opt.pretrained_state))\n",
    "logger.info('Snapshot will be saved in \"{}\"'.format(opt.save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.networks import define_D, GANLoss, define_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_network(network, basename, gpu_ids):\n",
    "    save_filename = '{}.pth'.format(basename)\n",
    "    save_path = os.path.join(opt.save_dir, save_filename)\n",
    "    torch.save(network.cpu().state_dict(), save_path)\n",
    "    network.cuda(device_id=opt.gpu_ids[0])\n",
    "    logger.info('A model was saved to \"{}\"'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_optimizer(optimizer, basename):\n",
    "    save_filename = '{}.pth'.format(basename)\n",
    "    save_path = os.path.join(opt.save_dir, save_filename)\n",
    "    torch.save(optimizer.state_dict(), save_path)\n",
    "    logger.info('A optimizer state was saved to \"{}\"'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def save_history(dict_history, basename):\n",
    "#     save_filename = os.path.join(opt.save_dir, 'loss_history_{}.pkl'.format(basename))\n",
    "#     with open(save_filename, 'w') as f:\n",
    "#         pk.dump(save_filename, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO no_lsgan and use sigmoid\n",
    "opt.use_sigmoid = opt.no_lsgan\n",
    "model_D = define_D(6, 64, 'basic', use_sigmoid=opt.use_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_G = define_G(3, 3, 64, which_model_netG='unet_256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/dist-packages')\n",
    "\n",
    "from graphviz import Digraph\n",
    "from visualize import make_dot\n",
    "\n",
    "g = make_dot(model_G)\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_history = {\n",
    "    'L2_loss': [],\n",
    "    'Gan_G_loss': [], \n",
    "    'D_loss_real': [],\n",
    "    'D_loss_fake': [],\n",
    "}\n",
    "\n",
    "if opt.pretrained_state is None:\n",
    "    state = {\n",
    "        'loss_history': {\n",
    "            'L2_loss': [],\n",
    "            'Gan_G_loss': [], \n",
    "            'D_loss_real': [],\n",
    "            'D_loss_fake': [],\n",
    "        },\n",
    "        'model_G': None,\n",
    "        'model_D': None,\n",
    "        'optimizer_G': None,\n",
    "        'optimizer_D': None,        \n",
    "        \n",
    "        'epochs': 0\n",
    "    }\n",
    "    model_G.apply(weights_init)\n",
    "    model_D.apply(weights_init)\n",
    "    model_G.cuda(device_id=opt.gpu_ids[0])\n",
    "    model_D.cuda(device_id=opt.gpu_ids[0])\n",
    "    optimizer_G = torch.optim.Adam(model_G.parameters(), lr=opt.learning_rate)\n",
    "    optimizer_D = torch.optim.Adam(model_D.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "else:\n",
    "    with open(opt.pretrained_state) as f:\n",
    "        state = pk.load(f)\n",
    "    model_G.load_state_dict(torch.load(os.path.join(os.path.dirname(opt.pretrained_state), state['model_G'])))\n",
    "    model_D.load_state_dict(torch.load(os.path.join(os.path.dirname(opt.pretrained_state), state['model_D'])))\n",
    "    model_G.cuda(device_id=opt.gpu_ids[0])\n",
    "    model_D.cuda(device_id=opt.gpu_ids[0])\n",
    "    optimizer_G = torch.optim.Adam(model_G.parameters(), lr=opt.learning_rate)\n",
    "    optimizer_D = torch.optim.Adam(model_D.parameters(), lr=opt.learning_rate)\n",
    "    optimizer_G.load_state_dict(torch.load(os.path.join(os.path.dirname(opt.pretrained_state), state['optimizer_G'])))\n",
    "    optimizer_D.load_state_dict(torch.load(os.path.join(os.path.dirname(opt.pretrained_state), state['optimizer_D'])))   \n",
    "    \n",
    "    \n",
    "    \n",
    "loss_history = state['loss_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gan_loss = GANLoss(tensor = Tensor, use_lsgan = not opt.no_lsgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "if opt.dataset == 'starcraft':\n",
    "    from datasets.starcraft import StarCraftDataset\n",
    "    starcraft = StarCraftDataset('/home/guang/datasets/starcraft', N=opt.num_crops_per_image)\n",
    "    dataset = torch.utils.data.DataLoader(\n",
    "                starcraft,\n",
    "                batch_size=opt.num_images_per_batch,\n",
    "                num_workers=int(1),\n",
    "                shuffle=True)\n",
    "    n_image_pairs = len(starcraft)\n",
    "elif opt.dataset == 'ilsvrc2012':\n",
    "    from datasets.ilsvrc2012 import ILSVRC2012\n",
    "    ilsvrc = ILSVRC2012('/home/guang/datasets/ILSVRC2012', N=opt.num_crops_per_image, scales=[2,3,4])\n",
    "    dataset = torch.utils.data.DataLoader(\n",
    "                ilsvrc,\n",
    "                batch_size=opt.num_images_per_batch,\n",
    "                num_workers=int(1),\n",
    "                shuffle=True)\n",
    "elif opt.dataset == 'starcraft1688':\n",
    "    from datasets.starcraft1688 import StarCraft1688Dataset\n",
    "    starcraft = StarCraft1688Dataset('/home/guang/datasets/starcraft1688', N=opt.num_crops_per_image)\n",
    "    dataset = torch.utils.data.DataLoader(\n",
    "                starcraft,\n",
    "                batch_size=opt.num_images_per_batch,\n",
    "                num_workers=int(1),\n",
    "                shuffle=True)\n",
    "    n_image_pairs = len(starcraft)    \n",
    "if opt.num_average_minibatches is None:\n",
    "    opt.num_average_minibatches = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis = visdom.Visdom(port=opt.display_port)\n",
    "vis.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_snapshot(model_G, model_D, optimizer_G, optimizer_D, state, epochs, iterations=0, save_state=True):\n",
    "    epoch_txt = \"_epoch{}_iter{}\".format(epoch, iterations)\n",
    "    save_network(model_G, opt.snapshot_prefix_G+epoch_txt, opt.gpu_ids[0])\n",
    "    save_network(model_D, opt.snapshot_prefix_D+epoch_txt, opt.gpu_ids[0])\n",
    "    \n",
    "    if save_state:\n",
    "        save_optimizer(optimizer_G, opt.snapshot_prefix_G+'_optimizer'+epoch_txt)\n",
    "        save_optimizer(optimizer_D, opt.snapshot_prefix_D+'_optimizer'+epoch_txt)  \n",
    "        state['model_G'] = opt.snapshot_prefix_G+epoch_txt+'.pth'\n",
    "        state['model_D'] = opt.snapshot_prefix_D+epoch_txt+'.pth'\n",
    "        state['optimizer_G'] = opt.snapshot_prefix_G+'_optimizer'+epoch_txt+'.pth'\n",
    "        state['optimizer_D'] = opt.snapshot_prefix_D+'_optimizer'+epoch_txt+'.pth'\n",
    "        state['epochs'] = epochs\n",
    "        state['iterations'] = iterations\n",
    "        with open(os.path.join(opt.save_dir, 'state{}.pkl'.format(epoch_txt)), 'w') as f:\n",
    "                pk.dump(state, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import progressbar as pb\n",
    "\n",
    "input_tensor = Tensor(1, 3, 256, 256)\n",
    "target_tensor = Tensor(1, 3, 256, 256)\n",
    "# label_fake = Variable(Tensor(opt.batch_size).fill_(0))\n",
    "# label_real = Variable(Tensor(opt.batch_size).fill_(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epoch_start_with = state['epochs']\n",
    "for epoch in range(epoch_start_with, opt.max_epochs+1):\n",
    "    if epoch != epoch_start_with and (epoch) % opt.snapshot_interval_epochs == 0:\n",
    "        save_snapshot(model_G, model_D, optimizer_G, optimizer_D, state, epoch, iterations=0)\n",
    "        \n",
    "    if epoch == opt.max_epochs:\n",
    "        break\n",
    "    \n",
    "    widgets = [\n",
    "        'Epoch {}: '.format(epoch), pb.Percentage(),\n",
    "        ' ', pb.Bar(marker=pb.AnimatedMarker()),\n",
    "        ' ', pb.ETA()\n",
    "    ]\n",
    "    bar = pb.ProgressBar(widgets=widgets, maxval=len(dataset)).start()\n",
    "\n",
    "    \n",
    "    batch_L2_loss = []\n",
    "    batch_D_loss_real = []\n",
    "    batch_D_loss_fake = []\n",
    "    for minibatch_i, data in enumerate(dataset):\n",
    "        \n",
    "        if opt.snapshot_interval_epochs <= 1 and minibatch_i > 0 and minibatch_i % opt.snapshot_interval_iters == 0:\n",
    "            save_snapshot(model_G, model_D, optimizer_G, optimizer_D, state, epoch, minibatch_i, False)\n",
    "        \n",
    "        log_msg = 'epoch {}, minibatch {}/{}'.format(epoch, minibatch_i, len(dataset))\n",
    "        #vis.text(log_msg, win=0)\n",
    "        # Stacking crops together as different inputs/targets\n",
    "        input_data = []\n",
    "        target_data = []\n",
    "        for crop_i in range(opt.num_crops_per_image):\n",
    "            input_data.append(data[crop_i*2])\n",
    "            target_data.append(data[crop_i*2+1])\n",
    "        input_data = torch.cat(input_data, dim=0)    \n",
    "        target_data = torch.cat(target_data, dim=0)       \n",
    "        \n",
    "        input_tensor.resize_(input_data.size()).copy_(input_data)\n",
    "        target_tensor.resize_(target_data.size()).copy_(target_data)\n",
    "        input = Variable(input_tensor)\n",
    "        target = Variable(target_tensor)\n",
    "        output = model_G.forward(input)\n",
    "        D_score_fake = model_D.forward(torch.cat((input, output), 1)) #####\n",
    "        \n",
    "        L2_loss = torch.nn.MSELoss()(output, target)\n",
    "        GAN_loss_G = gan_loss(D_score_fake, True)\n",
    "        G_loss = L2_loss + GAN_loss_G * opt.lambda_G\n",
    "    \n",
    "        optimizer_G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        batch_L2_loss_cpu = L2_loss.data.cpu().numpy()[0]\n",
    "        batch_L2_loss.append(batch_L2_loss_cpu)\n",
    "        log_msg += '\\tL2_loss: {:.6f}'.format(batch_L2_loss_cpu)\n",
    "\n",
    "#\n",
    "        output = model_G.forward(input)\n",
    "        D_score_fake = model_D.forward(torch.cat((input, output), 1)) #####\n",
    "        D_score_real = model_D.forward(torch.cat((input, target), 1))\n",
    "        D_loss_real = gan_loss(D_score_real, True)\n",
    "        D_loss_fake = gan_loss(D_score_fake, False)\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        D_loss_real_cpu = D_loss_real.data.cpu().numpy()[0]\n",
    "        D_loss_fake_cpu = D_loss_fake.data.cpu().numpy()[0]        \n",
    "        \n",
    "        batch_D_loss_real.append(D_loss_real_cpu)\n",
    "        batch_D_loss_fake.append(D_loss_fake_cpu)\n",
    "        \n",
    "        log_msg += '\\tD_loss_real: {:.6f}'.format(D_loss_real_cpu)\n",
    "        log_msg += '\\tD_loss_fake: {:.6f}'.format(D_loss_fake_cpu)\n",
    "        logger.info(log_msg)\n",
    "        \n",
    "        vis.text(log_msg, win=1, env=opt.display_env)\n",
    "        bar.update(minibatch_i + 1)\n",
    "        \n",
    "        if opt.display_interval > 0 and minibatch_i % opt.display_interval==0:\n",
    "            #input_image = input.data.cpu().numpy()\n",
    "            \n",
    "            #vis.images(input_image*0.5 + 0.5, win=0, opts=dict(title='input_{}'.format(display_i), caption='LR'))            \n",
    "       \n",
    "            display_egs = torch.cat((input, output, target), dim=3)\n",
    "            display_egs = display_egs.data.cpu().numpy()\n",
    "            mean = [ 0.5, 0.5, 0.5 ]\n",
    "            std = [ 0.5, 0.5, 0.5 ]\n",
    "            for c in range(3):\n",
    "                pass\n",
    "                display_egs[:, c, :, :] *= std[c]\n",
    "                display_egs[:, c, :, :] += mean[c]\n",
    "\n",
    "            for display_i in range(min(opt.num_images_per_batch, 6)):\n",
    "                vis.image(display_egs[display_i,:,:,:], win=100+display_i, env=opt.display_env)\n",
    "           \n",
    "    bar.finish()\n",
    "    \n",
    "    loss_history['L2_loss'].append(np.array(batch_L2_loss).mean())\n",
    "    loss_history['D_loss_real'].append(np.array(batch_D_loss_real).mean())\n",
    "    loss_history['D_loss_fake'].append(np.array(batch_D_loss_fake).mean()) \n",
    "    \n",
    "    \n",
    "    epoch_loss_message = '------[AVG]------'\n",
    "    epoch_loss_message += '\\t\\tL2_loss: {:.6f}\\tD_loss_real: {:.6f}\\tD_loss_fake: {:.6f}'.format(loss_history['L2_loss'][-1], \n",
    "                                                                                  loss_history['D_loss_real'][-1], \n",
    "                                                                                  loss_history['D_loss_fake'][-1])\n",
    "    logger.info(epoch_loss_message)   \n",
    "    print epoch_loss_message\n",
    "\n",
    "    vis.line(Y=np.array([loss_history['L2_loss'], \n",
    "                         loss_history['D_loss_real'], \n",
    "                         loss_history['D_loss_fake']]).T, \n",
    "                         X=np.arange(len(loss_history['L2_loss']))+1, win=3, env=opt.display_env, \n",
    "             opts={\n",
    "                'title': 'loss over time',\n",
    "                'xlabel': 'epoch',\n",
    "                'ylabel': 'loss' ,\n",
    "                'ytype': 'log',\n",
    "                'legend': ['L2','D_real','D_fake']},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_state_dict(torch.load(save_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_G.load_state_dict(torch.load('/home/guang/SuperRes/pytorch-sr-gan/snapshots/3400_net_G.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from torchvision.datasets.folder import is_image_file, default_loader, find_classes, make_dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_list = [transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                       (0.5, 0.5, 0.5))]\n",
    "transform_norm = transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_lr = default_loader('/home/guang/SuperRes/test/lr/starcraft2_1.bmp.png')\n",
    "img_lr = transform_norm(img_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "256*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_lr = img_lr[:, :1024, :1792].cuda()\n",
    "c, h, w = img_lr.size()\n",
    "test_image = Variable(img_lr).view(1, c, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model_G(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_image = pred.data.cpu().numpy()\n",
    "vis.image(pred_image[0,:,:,:]*0.5 + 0.5, win=0, opts=dict(title='pred')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Image.open('/home/guang/datasets/ILSVRC2012/train/n03127925/n03127925_396.JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.randint(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, h = img.size\n",
    "th, tw = ()\n",
    "if w == tw and h == th:\n",
    "    return img\n",
    "x1 = random.randint(0, w - tw)\n",
    "y1 = random.randint(0, h - th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_network(model_G, opt.snapshot_prefix_G, epoch, opt.gpu_ids[0])torchvision\n",
    "save_network(model_D, opt.snapshot_prefix_D, epoch, opt.gpu_ids[0])\n",
    "save_optimizer(optimizer_G, opt.snapshot_prefix_G+'_optimizer', epoch)\n",
    "save_optimizer(optimizer_D, opt.snapshot_prefix_D+'_optimizer', epoch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_for_vgg = transforms.Normalize((0.0, 0.0, 0.0),(0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_vgg = input * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16.cuda(device_id=opt.gpu_ids[0])\n",
    "vgg16(input * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transforms.CenterCrop(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (env:RUSALKA)",
   "language": "python",
   "name": "rusalka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
